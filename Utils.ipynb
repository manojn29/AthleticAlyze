{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To remove duplicates\n",
    "import pandas as pd\n",
    "file_name_output = \"Dir0/final.csv\"\n",
    "file_name = \"Dir0/combined_csv.csv\"\n",
    "df = pd.read_csv(file_name, sep=\",\")\n",
    "df.drop_duplicates('id', keep = 'last', inplace=True)\n",
    "df.to_csv(file_name_output, index=False)\n",
    "\n",
    "# Alternate code for large file\n",
    "import hashlib\n",
    "\n",
    "# Create a set to store unique 'id' values\n",
    "unique_ids = set()\n",
    "\n",
    "# Open the input and output files\n",
    "with open(\"combined_csv_ALL.csv\", \"r\") as input_file, open(\"final_ALL.csv\", \"w\") as output_file:\n",
    "    # Write the header row to the output file\n",
    "    header = input_file.readline()\n",
    "    output_file.write(header)\n",
    "    \n",
    "    # Iterate through the rest of the rows in the input file\n",
    "    for line in input_file:\n",
    "        # Split the line into fields\n",
    "        fields = line.strip().split(\",\")\n",
    "        \n",
    "        # Extract the 'id' field\n",
    "        current_id = fields[0]\n",
    "        \n",
    "        # Check if the 'id' value is already in the set\n",
    "        if current_id not in unique_ids:\n",
    "            # If it's not, add it to the set\n",
    "            unique_ids.add(current_id)\n",
    "            \n",
    "            # Write the row to the output file\n",
    "            output_file.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To combine csv files\n",
    "import pandas as pd\n",
    "extension = 'csv'\n",
    "import os, glob\n",
    "all_filenames = [i for i in glob.glob('*.{}'.format(extension))]\n",
    "combined_csv = pd.concat([pd.read_csv(f) for f in all_filenames ])\n",
    "combined_csv.to_csv( \"combined_csv.csv\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To add hashtags to each column\n",
    "import pandas as pd \n",
    "import csv \n",
    "import re\n",
    "\n",
    "df = pd.read_csv(\"final.csv\")\n",
    "for i, tweet in df.iterrows():\n",
    "  tags = re.findall(r'#\\w+', tweet[\"tweet\"])\n",
    "  tagCol = ' '.join(tags)\n",
    "  df.at[i, 'hashtag'] = tagCol\n",
    "\n",
    "df.to_csv('final_manoj_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To remove column from csv\n",
    "\n",
    "import pandas as pd\n",
    "# read_csv function which is used to read the required CSV file\n",
    "data = pd.read_csv('final_manoj_dataset.csv')\n",
    "  \n",
    "data.drop('screen_name', inplace=True, axis=1)\n",
    "\n",
    "data.to_csv('withoutsn.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To check duplicate rows in csv\n",
    "import csv\n",
    "distinct = set()\n",
    "fullcount = 0\n",
    "filename = \"Dir0/final.csv\"\n",
    "duplicates = []\n",
    "with open(filename, 'r', newline='') as file:\n",
    "    reader = csv.reader(file)\n",
    "    next(reader, None)\n",
    "    for row in reader:\n",
    "        if str(row[0]) in distinct:\n",
    "            duplicates.append(str(row[0]))\n",
    "        fullcount += 1\n",
    "        distinct.add(str(row[0]))\n",
    "\n",
    "print(\"Full count:\", fullcount)\n",
    "print(\"distinct count\", len(distinct))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d1a6dc045fad8e521d8162989fccd257812e908a0cedf189f97eca95d02c1612"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
