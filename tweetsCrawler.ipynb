{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of tweets:  0\n"
     ]
    }
   ],
   "source": [
    "import tweepy\n",
    "import csv, os\n",
    "import threading, random\n",
    "\n",
    "consumer_key = \"\"\n",
    "consumer_secret = \"\"\n",
    "access_token = \"\"\n",
    "access_token_secret = \"\"\n",
    "\n",
    "tweetsPerQry = 100\n",
    "maxTweets = 100\n",
    "# Add 5 hashtag comma separated\n",
    "hashtag = \"\"\n",
    "\n",
    "authentication = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "authentication.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(authentication, wait_on_rate_limit=True)\n",
    "maxId = -1\n",
    "tweetCount = 0\n",
    "\n",
    "tweetIds = set()\n",
    "\n",
    "def writeTweets(filename, tag):\n",
    "  global tweetCount, maxId, tweetIds\n",
    "  fileExists = os.path.exists(filename)\n",
    "\n",
    "  if fileExists:\n",
    "    with open(filename, 'r', newline='') as file:\n",
    "      reader = csv.reader(file)\n",
    "      next(reader, None)\n",
    "      for row in reader:\n",
    "        tweetIds.add(str(row[0]))\n",
    "  with open(filename, 'a', newline='', encoding='utf8') as csvFile:\n",
    "    fieldNames = ['id', 'tweet', 'time', 'lat', 'long']\n",
    "    writer = csv.DictWriter(csvFile, fieldnames=fieldNames)\n",
    "    if not fileExists:\n",
    "        writer.writeheader()\n",
    "    while tweetCount < maxTweets:\n",
    "      if(maxId <= 0):\n",
    "        # newTweets = api.search(q=hashtag, count=tweetsPerQry, result_type=\"recent\", tweet_mode=\"extended\")\n",
    "        newTweets = api.search_tweets(q=tag, count=tweetsPerQry, result_type=\"recent\", tweet_mode=\"extended\")\n",
    "      else:\n",
    "        newTweets = api.search_tweets(q=tag, count=tweetsPerQry, max_id=str(maxId - 1), result_type=\"recent\", tweet_mode=\"extended\")\n",
    "      \n",
    "      # if not newTweets:\n",
    "      #   print(\"Tweet Habis\")\n",
    "      #   break\n",
    "      \n",
    "      for tweet in newTweets:\n",
    "        # if str(tweet.id) not in tweetIds and (tweet.coordinates or tweet.user.location):\n",
    "        if str(tweet.id) not in tweetIds:\n",
    "          lat = random.uniform(24.396308, 49.384358)\n",
    "          long = random.uniform(-124.848974, -66.885444)\n",
    "          tweetIds.add(tweet.id)\n",
    "          writer.writerow({'id': tweet.id, 'tweet': tweet.full_text.encode(encoding='utf8'), 'time': tweet.created_at, 'lat': lat, 'long': long})\n",
    "          # print(\"id:\", tweet.id, \"tweet:\", tweet.full_text.encode(encoding='utf8'), \"time:\", tweet.created_at, \"geo:\", tweet.user.location, \"enabled:\", tweet.user.geo_enabled)\n",
    "        \n",
    "      tweetCount += len(newTweets)\n",
    "      maxId = newTweets[-1].id\n",
    "print(\"Length of tweets: \", len(tweetIds))\n",
    "\n",
    "threads = []\n",
    "tags = hashtag.split(',')\n",
    "for i in range(8):\n",
    "  filename = \"twitterSportsData\" + str(i) + '.csv'\n",
    "  t = threading.Thread(target=writeTweets, args = (filename,tags[i],))\n",
    "  threads.append(t)\n",
    "  t.start()\n",
    "\n",
    "for t in threads:\n",
    "  t.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d1a6dc045fad8e521d8162989fccd257812e908a0cedf189f97eca95d02c1612"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
